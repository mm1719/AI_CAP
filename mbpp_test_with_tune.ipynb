{"cells":[{"cell_type":"code","source":["%%capture\n","# Installs Unsloth, Xformers (Flash Attention) and all other packages!\n","!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n","!pip install xformers trl peft accelerate bitsandbytes"],"metadata":{"id":"SkmsjMGq2PkQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_params = {\n","    'learning_rate': 0.0007804852426265795,\n","    'batch_size': 1,\n","    'warmup_steps': 3,\n","    'max_steps': 109,\n","    'weight_decay': 0.00031584871539798177,\n","    'dropout_rate': 0.4251796832408427,\n","}"],"metadata":{"id":"F9SacLO03lnR"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gMzJlcAP1gH0","executionInfo":{"status":"ok","timestamp":1716609103715,"user_tz":-480,"elapsed":13402,"user":{"displayName":"CAP AI","userId":"15143934473145264642"}},"outputId":"0dedd7e8-2b4f-47aa-a7ea-7d1e356106bc"},"outputs":[{"output_type":"stream","name":"stdout","text":["ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"]},{"output_type":"stream","name":"stderr","text":["Unsloth: You passed in `unsloth/Phi-3-mini-4k-instruct` and `load_in_4bit = True`.\n","We shall load `unsloth/Phi-3-mini-4k-instruct-bnb-4bit` for 4x faster loading.\n"]},{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth: Fast Mistral patching release 2024.5\n","   \\\\   /|    GPU: NVIDIA L4. Max memory: 22.168 GB. Platform = Linux.\n","O^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 8.9. CUDA Toolkit = 12.1.\n","\\        /    Bfloat16 = TRUE. Xformers = 0.0.26.post1. FA = False.\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"]},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["from unsloth import FastLanguageModel\n","import torch\n","max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n","dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n","load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n","\n","# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n","fourbit_models = [\n","    \"unsloth/mistral-7b-bnb-4bit\",\n","    \"unsloth/mistral-7b-instruct-v0.2-bnb-4bit\",\n","    \"unsloth/llama-2-7b-bnb-4bit\",\n","    \"unsloth/gemma-7b-bnb-4bit\",\n","    \"unsloth/gemma-7b-it-bnb-4bit\", # Instruct version of Gemma 7b\n","    \"unsloth/gemma-2b-bnb-4bit\",\n","    \"unsloth/gemma-2b-it-bnb-4bit\", # Instruct version of Gemma 2b\n","    \"unsloth/llama-3-8b-bnb-4bit\", # [NEW] 15 Trillion token Llama-3\n","] # More models at https://huggingface.co/unsloth\n","\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"unsloth/Phi-3-mini-4k-instruct\",\n","    max_seq_length = max_seq_length,\n","    dtype = dtype,\n","    load_in_4bit = load_in_4bit,\n","    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T6LScrUj1gH3"},"outputs":[],"source":["from datasets import load_dataset\n","dataset = load_dataset(\"mbpp\", split = \"train\")\n","validate_dataset = load_dataset(\"mbpp\", split = \"validation\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o3yYMrB81gH3","executionInfo":{"status":"ok","timestamp":1716609191302,"user_tz":-480,"elapsed":3797,"user":{"displayName":"CAP AI","userId":"15143934473145264642"}},"outputId":"6692d2b0-89f0-4363-9ee3-e786c90f51fa"},"outputs":[{"output_type":"stream","name":"stderr","text":["Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.4251796832408427.\n","Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n","Unsloth 2024.5 patched 32 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"]}],"source":["model = FastLanguageModel.get_peft_model(\n","    model,\n","    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n","    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n","    lora_alpha = 16,\n","    lora_dropout = best_params['dropout_rate'], # Supports any, but = 0 is optimized\n","    bias = \"none\",    # Supports any, but = \"none\" is optimized\n","    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n","    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n","    random_state = 3407,\n","    use_rslora = False,  # We support rank stabilized LoRA\n","    loftq_config = None, # And LoftQ\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k0h9Tq4C1gH4"},"outputs":[],"source":["import pandas as pd\n","\n","# Define your custom prompt template\n","alpaca_prompt = \"\"\"Write a Python code to solve the given problem, and the code should be able to run the test case.\n","\n","### Instruction:\n","{}\n","\n","### Test Case:\n","{}\n","\n","### Response:\n","{}\"\"\"\n","\n","# Define the EOS_TOKEN (replace 'tokenizer' with your actual tokenizer instance)\n","EOS_TOKEN = '<eos>'  # Example token, replace with tokenizer.eos_token\n","\n","# Function to format the dataset examples\n","def formatting_prompts_func(examples):\n","    instructions = examples[\"text\"]\n","    test_cases = examples[\"test_list\"] #give all test case\n","    outputs = examples[\"code\"]\n","    texts = []\n","\n","    for instruction , test_case, output in zip(instructions, test_cases, outputs):\n","\n","        # Format the text using the template and add EOS_TOKEN\n","        text = alpaca_prompt.format(instruction, test_case, output) + EOS_TOKEN\n","        texts.append(text)\n","\n","    return {\"text\": texts}\n","\n","# Apply the formatting function to the dataset\n","format_dataset = dataset.map(formatting_prompts_func, batched=True, remove_columns=dataset.column_names)\n","format_validate_dataset = validate_dataset.map(formatting_prompts_func, batched=True, remove_columns=validate_dataset.column_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HLKaw4E31gH4","executionInfo":{"status":"ok","timestamp":1716609198723,"user_tz":-480,"elapsed":420,"user":{"displayName":"CAP AI","userId":"15143934473145264642"}},"outputId":"9cb4a0e6-a8e4-4a1a-c2f2-d0a08d985d1d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Write a Python code to solve the given problem, and the code should be able to run the test case.\n","\n","### Instruction:\n","Write a function to find the longest chain which can be formed from the given set of pairs.\n","\n","### Test Case:\n","['assert max_chain_length([Pair(5, 24), Pair(15, 25),Pair(27, 40), Pair(50, 60)], 4) == 3', 'assert max_chain_length([Pair(1, 2), Pair(3, 4),Pair(5, 6), Pair(7, 8)], 4) == 4', 'assert max_chain_length([Pair(19, 10), Pair(11, 12),Pair(13, 14), Pair(15, 16), Pair(31, 54)], 5) == 5']\n","\n","### Response:\n","class Pair(object): \r\n","\tdef __init__(self, a, b): \r\n","\t\tself.a = a \r\n","\t\tself.b = b \r\n","def max_chain_length(arr, n): \r\n","\tmax = 0\r\n","\tmcl = [1 for i in range(n)] \r\n","\tfor i in range(1, n): \r\n","\t\tfor j in range(0, i): \r\n","\t\t\tif (arr[i].a > arr[j].b and\r\n","\t\t\t\tmcl[i] < mcl[j] + 1): \r\n","\t\t\t\tmcl[i] = mcl[j] + 1\r\n","\tfor i in range(n): \r\n","\t\tif (max < mcl[i]): \r\n","\t\t\tmax = mcl[i] \r\n","\treturn max<eos>\n"]}],"source":["print(format_dataset['text'][0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":191,"referenced_widgets":["bf8ad4c9ef4b4d4ab3355f1a933d31fa","7780a4f91ecc471dbfdf30f4cd05c67d","80b10e837cdc4546a488f4d84c191505","ddb15e9020a04320bcfa302ff3eebca0","2b192dfc730146a3945e46c43b4dc5eb","8088472096b14ab8b51077f9697498ef","dbb238d384a748cbab389fb53a02e3fc","56e17e67162c4e458eda10c3127822d9","7eb8e63e5fd64d5db7ca7a79f749fa23","888098cdf080418693e2e5809b4dbdc1","4cfc5394a358449888f6c6d269ea6320","8a71e6972614425498fe3c8301cbf777","b2ec12c82ad742fc852269eee0d25880","103443d07e6e4e1a8ec894f9b868c079","ec7d5fcb0c8443c98bbef63d13ba4d2c","361a16bbe51c4e5c8daec7cc2278a052","d6e073954a1d44dab5ceff3cf0543687","400d21363ee44373b49def8ec928dee8","fb6f3e3ca3744cf6a94adff2760fea94","b83e1839317a495bbe26c4141b2111c5","32f9b4324bc545b1ba1567849c0d6d3e","1ac913afcb784f4695e7dc168ba7ab3f"]},"id":"g_9eVVlb1gH4","executionInfo":{"status":"ok","timestamp":1716609244672,"user_tz":-480,"elapsed":1303,"user":{"displayName":"CAP AI","userId":"15143934473145264642"}},"outputId":"a0fcba53-d560-4338-e7ac-5bc1b9eb6a00"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"output_type":"display_data","data":{"text/plain":["Map (num_proc=2):   0%|          | 0/374 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf8ad4c9ef4b4d4ab3355f1a933d31fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map (num_proc=2):   0%|          | 0/90 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a71e6972614425498fe3c8301cbf777"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["max_steps is given, it will override any value given in num_train_epochs\n"]}],"source":["from trl import SFTTrainer\n","from transformers import TrainingArguments\n","\n","# Define TrainingArguments with the best hyperparameters\n","training_args = TrainingArguments(\n","    per_device_train_batch_size=best_params['batch_size'],\n","    gradient_accumulation_steps=4,\n","    warmup_steps=best_params['warmup_steps'],\n","    max_steps=best_params['max_steps'],\n","    learning_rate=best_params['learning_rate'],\n","    fp16=True,\n","    logging_steps=10,\n","    optim=\"adamw_8bit\",\n","    weight_decay=best_params['weight_decay'],\n","    lr_scheduler_type=\"linear\",\n","    seed=3407,\n","    output_dir=\"outputs\",\n","    evaluation_strategy=\"steps\",\n","    eval_steps=10,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"eval_loss\",\n",")\n","\n","# Initialize the trainer\n","trainer = SFTTrainer(\n","    model=model,\n","    tokenizer=tokenizer,\n","    train_dataset=format_dataset,\n","    eval_dataset=format_validate_dataset,\n","    dataset_text_field=\"text\",\n","    max_seq_length=2048,\n","    dataset_num_proc=2,\n","    packing=False,\n","    args=training_args,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":478},"id":"teGYMqmT1gH4","executionInfo":{"status":"ok","timestamp":1716609758593,"user_tz":-480,"elapsed":509379,"user":{"displayName":"CAP AI","userId":"15143934473145264642"}},"outputId":"b0e9ba76-a72d-4d8f-df22-5d05f95c7f28"},"outputs":[{"output_type":"stream","name":"stderr","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n","   \\\\   /|    Num examples = 374 | Num Epochs = 2\n","O^O/ \\_/ \\    Batch size per device = 1 | Gradient Accumulation steps = 4\n","\\        /    Total batch size = 4 | Total steps = 109\n"," \"-____-\"     Number of trainable parameters = 29,884,416\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [109/109 08:20, Epoch 1/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>1.081900</td>\n","      <td>0.578750</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.568300</td>\n","      <td>0.545433</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.564900</td>\n","      <td>0.530083</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.501300</td>\n","      <td>0.526712</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.554200</td>\n","      <td>0.520942</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.515700</td>\n","      <td>0.512320</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.558700</td>\n","      <td>0.505990</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.472800</td>\n","      <td>0.503826</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.519200</td>\n","      <td>0.497919</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.434500</td>\n","      <td>0.496085</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}],"source":["trainer_stats = trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CUC2urTM1gH4"},"outputs":[],"source":["from datasets import load_dataset\n","test_dataset = load_dataset(\"mbpp\", split = \"test\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fIUpyFyO1gH5","executionInfo":{"status":"ok","timestamp":1716611544652,"user_tz":-480,"elapsed":3747,"user":{"displayName":"CAP AI","userId":"15143934473145264642"}},"outputId":"10d18622-c65f-4e34-8972-c02906260dae"},"outputs":[{"output_type":"stream","name":"stdout","text":["<s> Write a Python code to solve the given problem, and the code should be able to run the test case.\n","\n","### Instruction:\n","Write a python function to remove first and last occurrence of a given character from the string.\n","\n","### Test Case:\n","assert remove_Occ(\"hello\",\"l\") == \"heo\"\n","\n","### Response:\n","def remove_Occ(str,char):\r\n","  str = str.replace(char, \"\")\r\n","  str = str.replace(char, \"\")\r\n","  return (str) <eos>\n","\n","<eos>\n","<|endoftext|>\n"]}],"source":["instruction = test_dataset['text'][0]\n","test_case = test_dataset['test_list'][0][0]\n","FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","inputs = tokenizer(\n","[\n","    alpaca_prompt.format(\n","        instruction, # instruction\n","        test_case,\n","        \"\", # output - leave this blank for generation!\n","    )\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","outputs = model.generate(**inputs, max_new_tokens = 2048, use_cache = True)\n","print(tokenizer.batch_decode(outputs)[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3cfKn7dS1gH5","executionInfo":{"status":"ok","timestamp":1716611563225,"user_tz":-480,"elapsed":311,"user":{"displayName":"CAP AI","userId":"15143934473145264642"}},"outputId":"cab0804c-dc39-4f09-b9c8-948287131e7c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Extracted Code:\n"," def remove_Occ(str,char):\r\n","  str = str.replace(char, \"\")\r\n","  str = str.replace(char, \"\")\r\n","  return (str)\n"]}],"source":["import re\n","# Define the regex pattern to extract code between \"### Response:\" and the first <eos>\n","pattern = re.compile(r\"### Response:\\s*(.*?)<eos>\", re.DOTALL)\n","\n","# Find all matches of the pattern in the decoded output\n","matches = pattern.findall(tokenizer.batch_decode(outputs)[0])\n","\n","# Extract the first match which is the desired code block\n","if matches:\n","    extracted_code = matches[0].strip()\n","    print(\"Extracted Code:\\n\", extracted_code)\n","else:\n","    print(\"No code block found.\")\n","\n","# Optional: further processing of the extracted code if needed"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jBhzzZWM1gH5","outputId":"1a994c11-1722-47d8-cdd2-8cda066be34d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Checkpoint saved at index 10\n","Checkpoint saved at index 20\n","Checkpoint saved at index 30\n","Checkpoint saved at index 40\n","Checkpoint saved at index 50\n","Checkpoint saved at index 60\n","Checkpoint saved at index 70\n","Checkpoint saved at index 80\n","Checkpoint saved at index 90\n","Checkpoint saved at index 100\n"]}],"source":["import re\n","import json\n","\n","# Define the regex pattern to extract code between \"### Response:\" and the first <eos>\n","pattern = re.compile(r\"### Response:\\s*(.*?)<eos>\", re.DOTALL)\n","\n","# Define the checkpoint frequency\n","checkpoint_frequency = 10\n","\n","# Load previous results if a checkpoint file exists\n","file = \"results.json\"\n","try:\n","    with open(file, \"r\") as f:\n","        results = json.load(f)\n","except FileNotFoundError:\n","    results = []\n","\n","# Determine the starting index based on the length of the existing results\n","start_index = len(results)\n","\n","for i in range(start_index, len(test_dataset['text'])):\n","    instruction = test_dataset['text'][i]\n","    test_case = test_dataset['test_list'][i][0]\n","    test_cases = test_dataset['test_list'][i]\n","    FastLanguageModel.for_inference(model)  # Enable native 2x faster inference\n","\n","    inputs = tokenizer(\n","        [\n","            alpaca_prompt.format(\n","                instruction,  # instruction\n","                test_case,\n","                \"\",  # output - leave this blank for generation!\n","            )\n","        ], return_tensors=\"pt\"\n","    ).to(\"cuda\")\n","\n","    outputs = model.generate(**inputs, max_new_tokens=2048, use_cache=True,)\n","\n","    generated_text = tokenizer.batch_decode(outputs)[0]\n","\n","    # Find all matches of the pattern in the generated output\n","    matches = pattern.findall(generated_text)\n","\n","    # Extract the first match which is the desired code block\n","    if matches:\n","        extracted_code = matches[0].strip()\n","    else:\n","        extracted_code = \"No code block found.\"\n","\n","    # Store the test case and extracted code as a pair\n","    results.append((test_cases, extracted_code))\n","\n","    # Save the checkpoint every 10 iterations\n","    if (i + 1) % checkpoint_frequency == 0:\n","        with open(file, \"w\") as f:\n","            json.dump(results, f, indent=4)\n","        print(f\"Checkpoint saved at index {i + 1}\")\n","\n","# Final save after the loop ends\n","with open(file, \"w\") as f:\n","    json.dump(results, f, indent=4)\n","print(\"Final checkpoint saved.\")\n","\n","# Display or save the results\n","for test_case, code in results:\n","    print(f\"Test Case: {test_case[0]}\\nExtracted Code:\\n{code[0]}\\n\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xx7R-pVo1gH5","outputId":"654a7f06-a9ef-483e-d167-78bece7c5868"},"outputs":[{"name":"stdout","output_type":"stream","text":["def sort_matrix(matrix):\n","\trow_sum = []\n","\tfor index, row in enumerate(matrix):\n","\t\trow_sum.append(sum(row))\n","\tmatrix.sort(key = lambda x: row_sum[matrix.index(x)])\n","\trow_sum.sort()# to get the index of the next smallest sum\n","\tfor index, row in enumerate(matrix):\n","\t\tif row_sum[index] == row_sum[index - 1]:\n","\t\t\t\tmatrix.remove(matrix[index - 1])\n","\t\t\t\tmatrix.insert(index - 1, matrix[-1])\n","\t\t\t\tmatrix.remove(matrix[-1])\n","\treturn matrix\n"]}],"source":["print(\"def sort_matrix(matrix):\\r\\n\\trow_sum = []\\r\\n\\tfor index, row in enumerate(matrix):\\r\\n\\t\\trow_sum.append(sum(row))\\r\\n\\tmatrix.sort(key = lambda x: row_sum[matrix.index(x)])\\r\\n\\trow_sum.sort()# to get the index of the next smallest sum\\r\\n\\tfor index, row in enumerate(matrix):\\r\\n\\t\\tif row_sum[index] == row_sum[index - 1]:\\r\\n\\t\\t\\t\\tmatrix.remove(matrix[index - 1])\\r\\n\\t\\t\\t\\tmatrix.insert(index - 1, matrix[-1])\\r\\n\\t\\t\\t\\tmatrix.remove(matrix[-1])\\r\\n\\treturn matrix\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"bf8ad4c9ef4b4d4ab3355f1a933d31fa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7780a4f91ecc471dbfdf30f4cd05c67d","IPY_MODEL_80b10e837cdc4546a488f4d84c191505","IPY_MODEL_ddb15e9020a04320bcfa302ff3eebca0"],"layout":"IPY_MODEL_2b192dfc730146a3945e46c43b4dc5eb"}},"7780a4f91ecc471dbfdf30f4cd05c67d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8088472096b14ab8b51077f9697498ef","placeholder":"â€‹","style":"IPY_MODEL_dbb238d384a748cbab389fb53a02e3fc","value":"Mapâ€‡(num_proc=2):â€‡100%"}},"80b10e837cdc4546a488f4d84c191505":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_56e17e67162c4e458eda10c3127822d9","max":374,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7eb8e63e5fd64d5db7ca7a79f749fa23","value":374}},"ddb15e9020a04320bcfa302ff3eebca0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_888098cdf080418693e2e5809b4dbdc1","placeholder":"â€‹","style":"IPY_MODEL_4cfc5394a358449888f6c6d269ea6320","value":"â€‡374/374â€‡[00:00&lt;00:00,â€‡599.10â€‡examples/s]"}},"2b192dfc730146a3945e46c43b4dc5eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8088472096b14ab8b51077f9697498ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dbb238d384a748cbab389fb53a02e3fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"56e17e67162c4e458eda10c3127822d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7eb8e63e5fd64d5db7ca7a79f749fa23":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"888098cdf080418693e2e5809b4dbdc1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4cfc5394a358449888f6c6d269ea6320":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8a71e6972614425498fe3c8301cbf777":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b2ec12c82ad742fc852269eee0d25880","IPY_MODEL_103443d07e6e4e1a8ec894f9b868c079","IPY_MODEL_ec7d5fcb0c8443c98bbef63d13ba4d2c"],"layout":"IPY_MODEL_361a16bbe51c4e5c8daec7cc2278a052"}},"b2ec12c82ad742fc852269eee0d25880":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6e073954a1d44dab5ceff3cf0543687","placeholder":"â€‹","style":"IPY_MODEL_400d21363ee44373b49def8ec928dee8","value":"Mapâ€‡(num_proc=2):â€‡100%"}},"103443d07e6e4e1a8ec894f9b868c079":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb6f3e3ca3744cf6a94adff2760fea94","max":90,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b83e1839317a495bbe26c4141b2111c5","value":90}},"ec7d5fcb0c8443c98bbef63d13ba4d2c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_32f9b4324bc545b1ba1567849c0d6d3e","placeholder":"â€‹","style":"IPY_MODEL_1ac913afcb784f4695e7dc168ba7ab3f","value":"â€‡90/90â€‡[00:00&lt;00:00,â€‡200.00â€‡examples/s]"}},"361a16bbe51c4e5c8daec7cc2278a052":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6e073954a1d44dab5ceff3cf0543687":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"400d21363ee44373b49def8ec928dee8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb6f3e3ca3744cf6a94adff2760fea94":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b83e1839317a495bbe26c4141b2111c5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"32f9b4324bc545b1ba1567849c0d6d3e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ac913afcb784f4695e7dc168ba7ab3f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}